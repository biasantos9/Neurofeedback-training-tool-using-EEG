{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from mne.time_frequency import psd_array_multitaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd()\n",
    "\n",
    "#Dataframe com os dados originais\n",
    "dataframes_original = {}\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "    #Escolher só os files que terminem com 1.csv\n",
    "    if file.endswith('1.csv'):\n",
    "        if 'subject' in file:\n",
    "\n",
    "            file_path = os.path.join(data_path, file)\n",
    "            df = pd.read_csv(file_path) # df armazena os dados dos files\n",
    "            \n",
    "            data = df.iloc[:, 1:5]  # data fica com as colunas 2 a 5\n",
    "            \n",
    "            # Sujeito e estado conforme indicado no nome \n",
    "            sujeito = file.split('subject')[1][0]\n",
    "            estado = file.split('-')[1]\n",
    "\n",
    "            key = (estado, sujeito)\n",
    "            if key not in dataframes_original:\n",
    "                dataframes_original[key] = []\n",
    "            dataframes_original[key].append(data)\n",
    "\n",
    "\n",
    "# Parâmetros dos filtros\n",
    "notch_freq = 50 # Notch\n",
    "quality_factor = 40\n",
    "fs = 256  # Sampling rate in Hz\n",
    "time_interval = 1.0 / fs  # Time interval between samples\n",
    "highcut = 90 # Low-pass\n",
    "lowcut = 4 # High-pass\n",
    "order = 8\n",
    "\n",
    "# Aplicação dos parâmetros dos filtros\n",
    "b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, fs)\n",
    "sos = signal.iirfilter(order, highcut, btype='lowpass', analog=False, ftype='butter', fs=256, output='sos')\n",
    "b_hp, a_hp = signal.butter(order, lowcut, btype='highpass', fs=256)\n",
    "\n",
    "dataframes_filtrado= {}\n",
    "\n",
    "# Low-pass e high-pass\n",
    "for key, dfs in dataframes_original.items():\n",
    "    dataframes_filtrado[key] = []\n",
    "    for df in dfs:\n",
    "        df_filtrado = pd.DataFrame(signal.sosfiltfilt(sos, df.values, axis=0), columns=df.columns)\n",
    "        df_filtrado_lphp = pd.DataFrame(signal.filtfilt(b_hp, a_hp, df_filtrado.values, axis=0), columns=df.columns)\n",
    "        dataframes_filtrado[key].append(df_filtrado_lphp)\n",
    "\n",
    "# Notch\n",
    "for key, dfs in dataframes_filtrado.items():\n",
    "    dataframes_filtrado[key] = []\n",
    "    for df in dfs:\n",
    "        filtered_channel=pd.DataFrame()\n",
    "        for channel in df.columns:\n",
    "            filtered_data = pd.DataFrame(signal.filtfilt(b_notch, a_notch, df[channel]))\n",
    "            filtered_channel[channel]=filtered_data\n",
    "        dataframes_filtrado[key].append(filtered_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_power(freq, magnitude, low_freq, high_freq):\n",
    "    mask = (freq >= low_freq) & (freq <= high_freq)\n",
    "    freq_interval = freq[mask]\n",
    "    magnitude_interval = magnitude[mask]\n",
    "    average_power = np.trapz(magnitude_interval, x=freq_interval)\n",
    "    return average_power\n",
    "\n",
    "# Banda de interesse\n",
    "beta = (12, 35)\n",
    "\n",
    "def extract_features(df, channel_prefix):\n",
    "    features = {}\n",
    "    mag_column = f'{channel_prefix}_psd'\n",
    "    if mag_column in df.columns:\n",
    "        mag_signal = df[mag_column]\n",
    "        freqs = df[f'{channel_prefix}_freq']\n",
    "        beta_power = calculate_average_power(freqs, mag_signal, beta[0], beta[1])\n",
    "        features[f'{channel_prefix}_beta_power'] = beta_power\n",
    "    return features\n",
    "\n",
    "dataframes_multitaper = {}\n",
    "\n",
    "for key, dfs in dataframes_filtrado.items():\n",
    "    dataframes_multitaper[key] = []\n",
    "    for df in dfs:\n",
    "        df_multitaper = pd.DataFrame()\n",
    "        for column in df.columns:\n",
    "            psd_mt, freq_mt = psd_array_multitaper(df[column], fs, normalization='full', verbose=0)\n",
    "            df_multitaper[f\"{column}_freq\"] = freq_mt\n",
    "            df_multitaper[f\"{column}_psd\"] = psd_mt\n",
    "        dataframes_multitaper[key].append(df_multitaper)\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for (condition, sujeito), dfs in dataframes_multitaper.items():\n",
    "    for df in dfs:\n",
    "        for channel_prefix in ['TP9', 'AF7', 'AF8', 'TP10']:\n",
    "            channel_features = extract_features(df, channel_prefix)\n",
    "            all_features.append({\n",
    "                'condition': condition,\n",
    "                'sujeito': sujeito,\n",
    "                'channel': channel_prefix,\n",
    "                **channel_features\n",
    "            })\n",
    "\n",
    "all_data = []\n",
    "labels = []\n",
    "\n",
    "for item in all_features:\n",
    "    values = [item[key] for key in item.keys() if key.endswith('_beta_power')]\n",
    "    all_data.append(values)\n",
    "    labels.append(item['condition'])\n",
    "\n",
    "# Converter listas para arrays numpy\n",
    "all_data = np.array(all_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "concentrating       1.00      1.00      1.00        16\n",
      "      neutral       1.00      1.00      1.00        16\n",
      "      relaxed       1.00      1.00      1.00        16\n",
      "\n",
      "     accuracy                           1.00        48\n",
      "    macro avg       1.00      1.00      1.00        48\n",
      " weighted avg       1.00      1.00      1.00        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create RF classifier\n",
    "rf_classifier = RandomForestClassifier(max_depth= None, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "\n",
    "# Ajuste dos modelos a todos os dados\n",
    "rf_classifier.fit(all_data, labels)\n",
    "y_pred = rf_classifier.predict(all_data)\n",
    "\n",
    "# Mapear os estados\n",
    "trials_dict = {'neutral': 0, 'relaxed': 1, 'concentrating': 2}\n",
    "y_pred_num = [trials_dict[label] for label in y_pred]\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

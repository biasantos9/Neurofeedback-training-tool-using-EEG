{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.metrics import classification_report\n",
    "from mne.time_frequency import psd_array_multitaper\n",
    "import pyxdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of column names does not match number of columns in EEG data. Adjusting...\n",
      "Warning: Number of column names does not match number of columns in EEG data. Adjusting...\n",
      "Warning: Number of column names does not match number of columns in EEG data. Adjusting...\n"
     ]
    }
   ],
   "source": [
    "data_path = os.getcwd()\n",
    "\n",
    "# Dataframe com os dados originais \n",
    "dataframes_original = {}\n",
    "xdf_files = [file for file in os.listdir(data_path) if file.endswith('.xdf')]\n",
    "\n",
    "for file in xdf_files:\n",
    "    estado = file.split('.')[0]  # Extrair o estado do nome do arquivo sem a extensão\n",
    "    streams, _ = pyxdf.load_xdf(os.path.join(data_path, file))\n",
    "    \n",
    "    eeg_data_found = False  # Flag para indicar se os dados EEG foram encontrados\n",
    "    \n",
    "    for stream in streams:     \n",
    "        if stream['info']['type'][0] == 'EEG':            \n",
    "            eeg_data = pd.DataFrame(stream['time_series'])\n",
    "            \n",
    "            # Extrai os nomes das colunas \n",
    "            channel_names = []\n",
    "            for channel_desc in stream['info']['desc'][0]['channels']:\n",
    "                if 'label' in channel_desc:\n",
    "                    channel_names.append(channel_desc['label'][0])   \n",
    "\n",
    "            # Verifica se o número de nomes de colunas corresponde ao número de colunas\n",
    "            if len(channel_names) != eeg_data.shape[1]:\n",
    "                print(\"Warning: Number of column names does not match number of columns in EEG data. Adjusting...\")\n",
    "                channel_names = [f\"Channel_{i+1}\" for i in range(eeg_data.shape[1])]\n",
    "            \n",
    "            # Define os nomes das colunas no DataFrame\n",
    "            eeg_data.columns = channel_names\n",
    "            key = estado\n",
    "            \n",
    "            if key not in dataframes_original:\n",
    "                dataframes_original[key] = []\n",
    "            dataframes_original[key].append(eeg_data)\n",
    "\n",
    "            eeg_data_found = True  # Define a flag como True\n",
    "            break  # Para de iterar sobre os streams após encontrar os dados de EEG\n",
    "            \n",
    "    if not eeg_data_found:\n",
    "        print(\"No EEG data found in file:\", file)\n",
    "\n",
    "# Parâmetros dos filtros\n",
    "notch_freq = 50 # Notch\n",
    "quality_factor = 40\n",
    "fs = 256  # Sampling rate in Hz\n",
    "time_interval = 1.0 / fs  # Time interval between samples\n",
    "highcut = 90 # Low-pass\n",
    "lowcut = 4 # High-pass\n",
    "order = 8\n",
    "\n",
    "# Aplicação dos parâmetros dos filtros\n",
    "b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, fs)\n",
    "sos = signal.iirfilter(order, highcut, btype='lowpass', analog=False, ftype='butter', fs=256, output='sos')\n",
    "b_hp, a_hp = signal.butter(order, lowcut, btype='highpass', fs=256)\n",
    "\n",
    "# Low-pass e high-pass\n",
    "dataframes_filtrado = {}\n",
    "for key, dfs in dataframes_original.items():\n",
    "    dataframes_filtrado[key] = []\n",
    "    for df in dfs:\n",
    "        df_filtrado = pd.DataFrame(signal.sosfiltfilt(sos, df.values, axis=0), columns=df.columns)\n",
    "        df_filtrado_lphp = pd.DataFrame(signal.filtfilt(b_hp, a_hp, df_filtrado.values, axis=0), columns=df.columns)\n",
    "        dataframes_filtrado[key].append(df_filtrado_lphp)\n",
    "\n",
    "# Notch\n",
    "for key, dfs in dataframes_filtrado.items():\n",
    "    dataframes_filtrado[key] = []\n",
    "    for df in dfs:\n",
    "        filtered_channel=pd.DataFrame()\n",
    "        for channel in df.columns:\n",
    "            filtered_data = pd.DataFrame(signal.filtfilt(b_notch, a_notch, df[channel]))\n",
    "            filtered_channel[channel]=filtered_data\n",
    "        dataframes_filtrado[key].append(filtered_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_power(freq, magnitude, low_freq, high_freq):\n",
    "    mask = (freq >= low_freq) & (freq <= high_freq)\n",
    "    freq_interval = freq[mask]\n",
    "    magnitude_interval = magnitude[mask]\n",
    "    average_power = np.trapz(magnitude_interval, x=freq_interval)\n",
    "    return average_power\n",
    "\n",
    "# Banda de interesse\n",
    "beta = (12, 35)\n",
    "\n",
    "def extract_features(df):\n",
    "    features = {}\n",
    "    for column in df.columns:\n",
    "        mag_signal = df[column]\n",
    "        beta_power = calculate_average_power(df.index, mag_signal, beta[0], beta[1])\n",
    "        features[f'_beta_power'] = beta_power\n",
    "    return features\n",
    "\n",
    "dataframes_multitaper = {}\n",
    "\n",
    "for key, dfs in dataframes_filtrado.items():\n",
    "    dataframes_multitaper[key] = []\n",
    "    for df in dfs:\n",
    "        df_multitaper = pd.DataFrame()\n",
    "        for column in df.columns:\n",
    "            psd_mt, freq_mt = psd_array_multitaper(df[column], fs, normalization='full', verbose=0)\n",
    "            channel_name = column.split('_')[0]  # Extrair o nome do canal do nome da coluna\n",
    "            df_multitaper[f\"{channel_name}_{column}_freq\"] = freq_mt\n",
    "            df_multitaper[column] = psd_mt  # Salvar os valores PSD diretamente\n",
    "        dataframes_multitaper[key].append(df_multitaper)\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for estado, dfs in dataframes_multitaper.items():\n",
    "    for df in dfs:\n",
    "        for channel_prefix in ['Chan1', 'Chan2', 'Chan3', 'Chan4']:\n",
    "            channel_features = extract_features(df)\n",
    "            all_features.append({\n",
    "                'condition': estado,\n",
    "                'channel': channel_prefix,\n",
    "                **channel_features\n",
    "            })\n",
    "\n",
    "all_data = []\n",
    "labels = []\n",
    "\n",
    "for item in all_features:\n",
    "    values = [item[key] for key in item.keys() if key.endswith('_beta_power')]\n",
    "    all_data.append(values)\n",
    "    labels.append(item['condition'])\n",
    "\n",
    "# Converter listas para arrays numpy\n",
    "all_data = np.array(all_data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "concentrating       1.00      1.00      1.00         4\n",
      "      neutral       1.00      1.00      1.00         4\n",
      "      relaxed       1.00      1.00      1.00         4\n",
      "\n",
      "     accuracy                           1.00        12\n",
      "    macro avg       1.00      1.00      1.00        12\n",
      " weighted avg       1.00      1.00      1.00        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create RF classifier\n",
    "rf_classifier = RandomForestClassifier(max_depth= None, min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "rf_classifier.fit(all_data, labels)\n",
    "y_pred = rf_classifier.predict(all_data)\n",
    "\n",
    "# Mapear os estados\n",
    "trials_dict = {'neutral': 0, 'relaxed': 1, 'concentrating': 2}\n",
    "y_pred_num = [trials_dict[label] for label in y_pred]\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
